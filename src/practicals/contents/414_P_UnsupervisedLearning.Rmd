```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = Sys.getenv("GRANOLARR_HOME"))
rm(list = ls())

# Libraries
library(tidyverse)
library(magrittr)
library(psych)
```

# Unsupervised machine learning

*[Stefano De Sabbata](https://stefanodesabbata.com)*

[This work](https://github.com/sdesabbata/granolarr) is licensed under the [GNU General Public License v3.0](https://www.gnu.org/licenses/gpl-3.0.html). Contains public sector information licensed under the [Open Government Licence v3.0](http://www.nationalarchives.gov.uk/doc/open-government-licence).

## Introduction

The field of **machine learning** sits at the intersection of computer science and statistics, and it is a core component of data science. According to Mitchell (1997), *"the field of machine learning is concerned with the question of how to construct computer programs that automatically improve with experience."*

Machine learning approaches are divided into two main types.

- **Supervised**:
    - training of a *"predictive"* model from data;
    - one (or more) attribute of the dataset is used to "predict" another attribute.

- **Unsupervised**:
    - discovery of *descriptive* patterns in data;
    - commonly used in data mining.
    
Clustering is a classic unsupervised machine learning task, which aims to *"automatically divides the data into* ***clusters*** *, or groups of similar items"*(Lantz, 2019). In computer science, a wide range of approaches has been developed to tackle clustering. Among those approaches, the most commons are centroid-based approaches (such as k-means) and hierarchical approaches. Other approaches include density based clustering methods (such as DBSCAN) and midex approaches (such as bagged clustering), which combine different aspects of centroid-based  and hierarchical approaches.

### K-means

The k-mean approach clusters $n$ observations ($x$) in $k$ clusters ($c$) by minimising the within-cluster sum of squares (WCSS) through an iterative process. That is, the algorithm calculates the distance between each observation (i.e., each case, object, row in the table) and the centroid of its cluster. The square values of those distances are summed up for each cluster, and then for the whole dataset. The aim of the algorithm is minimase that value.

$$WCSS = \sum_{c=1}^{k} \sum_{x \in c} (x - \overline{x}_c)^2$$

To minimise WCSS, while trying to identify `k` clusters, k-mean first randomly select `k` observations as initial centroids. Then, k-means repeats the two steps below. Every time k-means repeats those two steps the new centroids will be closer to the two actual center. The process continues until centroids don't change anymore (within a certain margin of error) or until it has reached a maximum number of iterations set by the analyst.

- **assignment step**: observations assigned to closest centroids
- **update step**: calculate means for each cluster, as new centroid


### Geodemographic Classification

In GIScience, clustering approaches are commonly used to create *geodemographic classifications*. For instance, [Gale *et al.*, 2016](http://josis.net/index.php/josis/article/view/232/150) created the [2011 Output Area Classification (2011 OAC)](https://maps.cdrc.ac.uk/#/geodemographics/oac11/default/BTTTFFT/12/-1.1233/52.6454/) starting from an initial set of 167 prospective variablesfrom the UK Census 2011.

In the process of creating the classification, 86 variables were removed from the initial set, including highly correlated variables that don't bring additional informatio to the classification process. Furthermore, 41 variable were retained as they were, whereas 40 were combined, to create final set of 60 variables. The k-mean approach was then applied to cluster the census Output Areas (OAs) into 8 supergroups, 26 groups and 76 subgroups.

The [paper](http://josis.net/index.php/josis/article/view/232/150) provides a detail report of the process. In particular, it is interesting to see how the authors applied a process of variable selection involving repeated clustering while excluding one variable, to see how the within sum of square measure (WCSS) would be affected. Variable that produced significantly higher WCSS when excluded were considered for exclusion from the final analysis, in order to increase the homogeneity of the clusters. 

Once the clustering is completed, the final step in geodemographic classification is the interpretation of the resulting cluster, which is commonly done by observing theaverage values of the variables for each cluster.

## Examples

Select a number of clusters k that maximizes the average silhouette.

```{r, echo=TRUE, eval=FALSE}
leicester_2011OAC_ages <- readr::read_csv("2011_OAC_Raw_uVariables_Leicester.csv")
```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
leicester_2011OAC <- readr::read_csv(paste0(Sys.getenv("GRANOLARR_HOME"), "/data/", "2011_OAC_Raw_uVariables_Leicester.csv"))
```

```{r}
# u086	Dwellings, Household Spaces and Accomodation Type	Count	Household_Spaces	Housing Type	Housing	Whole house or bungalow: Detached
# u087	Dwellings, Household Spaces and Accomodation Type	Count	Household_Spaces	Housing Type	Housing	Whole house or bungalow: Semi-detached
# u088	Dwellings, Household Spaces and Accomodation Type	Count	Household_Spaces	Housing Type	Housing	Whole house or bungalow: Terraced (including end-terrace)
# u089	Dwellings, Household Spaces and Accomodation Type	Count	Household_Spaces	Housing Type	Housing	Flats

leicester_dwellings <-
  leicester_2011OAC %>%
  dplyr::select(
    OA11CD, Total_Dwellings,
    u086:u090
  ) %>%
  # scale across
  dplyr::mutate(
    dplyr::across( 
      u086:u090,
      #scale
      function(x){ (x / Total_Dwellings) * 100 }
    )
  ) %>%
  # rename columns
  dplyr::rename_with(
    function(x){ paste0("perc_", x) },
    u086:u090
  )
```


### Terrace and semi-detached houses

```{r, message=FALSE, warning=FALSE}
# install.packages("GGally")
library(GGally)

leicester_dwellings %>%
  dplyr::select(perc_u087, perc_u088) %>%
  GGally::ggpairs(
    lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))
  )
```

```{r}
library(cluster)

# Data for elbow method
data_for_testing <-
  leicester_dwellings %>%
  dplyr::select(perc_u086:perc_u090)

# k values to be taken into account
testing_wcss <- rep(NA, 15)
testing_silhouette <- rep(NA, 15)

for (testing_k in 2:15){
  # Calculate kmeans
  kmeans_result <- 
    kmeans(
      data_for_testing, 
      centers = testing_k, 
      iter.max = 50
    )
  # Calculate WCSS
  testing_wcss[testing_k] <- 
    kmeans_result %$%
    tot.withinss
  
  # Calculate silhouette
  testing_silhouette[testing_k] <- 
    silhouette(
      kmeans_result %$% cluster, 
      data_for_testing %>% dist()
    ) %>%
    magrittr::extract(3) %>%
    mean()
}

# Plot
plot(2:15, testing_wcss[2:15], type="b", xlab="Number of Clusters", ylab="Within groups sum of squares", xlim=c(1,15))
abline(v=3, col="red")

plot(2:15, testing_silhouette[2:15], type="b", xlab="Number of Clusters", ylab="silhouette", xlim=c(1,15))
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
terr_sede_kmeans <- leicester_dwellings %>%
  dplyr::select(perc_u087, perc_u088) %>%
  stats::kmeans(centers=5, iter.max=50)

leicester_dwellings <- 
  leicester_dwellings %>%
  tibble::add_column(
    terr_sede_cluster = 
      terr_sede_kmeans %$% 
        cluster %>%
          as.character()
  )

```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
leicester_dwellings %>%
  dplyr::select(perc_u087, perc_u088, terr_sede_cluster) %>%
  GGally::ggpairs(
    mapping = aes(color = terr_sede_cluster),
    lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))
  )
```

```{r}
leicester_dwellings %>%
  group_by(terr_sede_cluster) %>%
  dplyr::mutate(
    avg_perc_u087 = mean(perc_u087), 
    avg_perc_u088 = mean(perc_u088)
  ) %>%
  dplyr::select(terr_sede_cluster, avg_perc_u087, avg_perc_u088) %>%
  tidyr::pivot_longer(
    cols = -terr_sede_cluster,
    names_to = "variable",
    values_to = "value"
  ) %>%
    ggplot(
    aes(
      x = variable,
      y = terr_sede_cluster %>% ordered(
        levels = c("3", "5","1", "4", "2")
      )
    )
  ) +
  geom_tile(
    aes(
      fill = value
    )
  ) +
  xlab("Variable") + ylab("Cluster") +
  #scale_fill_brewer(palette = "YlOrRd", direction = 1) +
  scale_fill_viridis_b(option = "inferno") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
  
```


### All dwelling types


```{r, message=FALSE, warning=FALSE}
# install.packages("GGally")
library(GGally)

leicester_dwellings %>%
  dplyr::select(perc_u086:perc_u090) %>%
  GGally::ggpairs(
    lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))
  )
```

```{r}
library(cluster)

# Data for elbow method
data_for_testing <-
  leicester_dwellings %>%
  dplyr::select(perc_u086:perc_u090)

# k values to be taken into account
testing_wcss <- rep(NA, 15)
testing_silhouette <- rep(NA, 15)

for (testing_k in 2:15){
  # Calculate kmeans
  kmeans_result <- 
    kmeans(
      data_for_testing, 
      centers = testing_k, 
      iter.max = 50
    )
  # Calculate WCSS
  testing_wcss[testing_k] <- 
    kmeans_result %$%
    tot.withinss
  
  # Calculate silhouette
  testing_silhouette[testing_k] <- 
    silhouette(
      kmeans_result %$% cluster, 
      data_for_testing %>% dist()
    ) %>%
    magrittr::extract(3) %>%
    mean()
}

# Plot
plot(2:15, testing_wcss[2:15], type="b", xlab="Number of Clusters", ylab="Within groups sum of squares", xlim=c(1,15))
abline(v=3, col="red")

plot(2:15, testing_silhouette[2:15], type="b", xlab="Number of Clusters", ylab="silhouette", xlim=c(1,15))
```


```{r, echo=TRUE, message=FALSE, warning=FALSE}
dwellings_kmeans <- leicester_dwellings %>%
  dplyr::select(perc_u086:perc_u090) %>%
  stats::kmeans(centers=7, iter.max=50)

leicester_dwellings <- 
  leicester_dwellings %>%
  tibble::add_column(
    dwellings_cluster = 
      dwellings_kmeans %$% 
        cluster %>%
          as.character()
  )

```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
leicester_dwellings %>%
  dplyr::select(perc_u086:perc_u090, dwellings_cluster) %>%
  GGally::ggpairs(
    mapping = aes(color = dwellings_cluster),
    lower = list(continuous = wrap("points", alpha = 0.3, size=0.1))
  )
```

```{r}

```



```{r cleanup, include=FALSE}
rm(list = ls())
```